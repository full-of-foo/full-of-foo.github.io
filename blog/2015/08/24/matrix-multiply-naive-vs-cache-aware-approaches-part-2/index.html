
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->

<head>


<meta charset="utf-8">
<meta http-equiv="cleartype" content="on">

<title>(╯°□°）╯︵ ┻━┻ Matrix Multiply: Naive vs Cache-Aware Approaches (Part 2) - </title>
<meta name="author" content="Anthony Troy">




<meta name="description" content="Matrix Multiplication Feels Bad In our last post
we talked about the implications of both sequential and parallel naive Matrix-Matrix multiplication &hellip;">

<meta name="keywords" content="concurrency java research blog ruby rails javascript coffeescript backbone modern tech hacks dublin">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Twitter Cards -->

  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content"">
  
  <meta name="twitter:title" content="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)">
  <meta name="twitter:description" content="Matrix Multiplication Feels Bad In our last post
we talked about the implications of both sequential and parallel naive Matrix-Matrix multiplication &hellip;">
  <meta name="twitter:creator" content="@devtoeknee">


<!-- Open Graph -->
<meta property="og:local" content="en_US">
<meta property="og:type" content="article">
<meta property="og:url" content="http:///blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2">
<meta property="og:title" content="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)">
<meta property="og:description" content="Matrix Multiplication Feels Bad In our last post
we talked about the implications of both sequential and parallel naive Matrix-Matrix multiplication &hellip;">

  <meta property="og:image" content="">

<meta property="og:site_name" content="">

<link rel="canonical" href="http:///blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2">
<link href="/favicon.png" rel="icon">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link href="/atom.xml" rel="alternate" title="" type="application/atom+xml">
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/javascripts/vendor/modernizr-2.6.2.custom.min.js"></script>



<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">


</head>

<body id="post" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpeg" alt="Anthony Troy photo" class="author-photo">
					<h4>Anthony Troy</h4>
					<p>Code Pirate, </br>Project Monkey</p>
				</li>
				<li><a target="_blank" href="//ie.linkedin.com/pub/anthony-troy/62/40a/743">Learn More</a></li>
				
				<li>
					<a target="_blank" href="http://twitter.com/devtoeknee"><i class="fa fa-twitter"></i> Twitter</a>
				</li>
				
				<li>
					<a target="_blank" href="http://github.com/full-of-foo"><i class="fa fa-github"></i> GitHub</a>
				</li>
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->




<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="/blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2/" rel="bookmark" title="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)">Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)</a></h1>
        
        <h2>August 24, 2015</h2>
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <h2>Matrix Multiplication Feels Bad</h2>

<p>In our <a href="/blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1/">last post</a>
we talked about the implications of both sequential and parallel naive <a href="http://en.wikipedia.org/wiki/Matrix_multiplication">Matrix-Matrix multiplication (MMM)</a>. Sadly we found that this classic triple for-loop approach suffers from
<strong><a href="http://en.wikipedia.org/wiki/Locality_of_reference">poor locality</a></strong>.</p>

<p><img src="/images/pepe.png" alt="psad" />
OMG, who would have known? Our algorithms actually sometimes need to be cache-aware.</p>

<p>This time around we will look at the tall cache
assumption along with <a href="https://en.wikipedia.org/wiki/Loop_tiling">loop-tiling</a> applied to parallel and
sequential MMM. As you would expect there are also some pretty
benchmarks involved.</p>

<h2>Cache-Awareness, So Confuse</h2>

<p>In easy terms, most of the transfers between cache and disk simply involve blocks of data. Whereby the disk is partitioned into blocks of <strong>B</strong> elements each, and accessing one element on disk copies its entire block to cache. When assuming a tall cache, the cache can store up to <strong>M/B</strong> blocks, for a total size of <strong>M</strong> elements, <strong>M &#8805; B&sup2;</strong>.</p>

<p>Meaning when the cache is already full and a block is grabbed from disk, then another block will be evicted from cache. Before exploring something more cache-aware let us demonstrate this occurring in our naive (and cache-oblivious) solution. Assuming square matrices which do not fit into a tall cache then</p>

<p style="text-align:center;">n = rowAmountOfA = colAmountOfA = rowAmountOfB</p>

<p style="text-align:center;">n > M/B</p>

<p>Bellow we see the row-major layout of matrices <strong>A</strong> and <strong>B</strong>. We depict the red rectangles in matrix <strong>B</strong> as our blocks of cache. For all rows of matrix <strong>A</strong> we traverse over each column of <strong>B</strong>. Upon traversing <strong>B</strong> the accessing of each element is cached. Given that <strong>n = colAmountOfA</strong> and <strong>n > M/B</strong> then before the traversal of a column <strong>B</strong> completes the first, and possibly several subsequent, cached blocks of <strong>B</strong> will be evicted. So upon the next and remaining traversals of <strong>B</strong> we incur cache-misses on each block</p>

<p><img src="/images/naive.png" alt="m" /></p>

<p>From this we can be quite clever and infer that a naive algorithm with <strong>n > M/B</strong> results gets the following work done</p>

<p style="text-align:center;">Q(n) = Θ(n<sup>3</sup>)</p>

<p>Which implies that a naive algorithm with <strong>n &#8804; M/B</strong> will get the following work done since the second matrix can now exploit spatial locality</p>

<p style="text-align:center;">Q(n) = Θ(n<sup>3</sup>)/B</p>

<h2>Loop-Tiling, Feels Good</h2>

<p>Lets take a look at a standard <a href="https://en.wikipedia.org/wiki/Loop_tiling">tiling</a> solution to resolve our cache capacity misses.
<img src="/images/good.png" alt="good" /></p>

<p>Pro tip: <em>loop-tiling is a type of loop transformation on which many cache blocking algorithms are built.</em></p>

<p>It involves a combination of strip-mining and interchange in multiply-nested loops, in turn strip-mines several nested loops and performs interchanges to bring the strip-loops inward.</p>

<p>This following tiling solution ensures greater spatial locality for accesses across matrix <strong>B</strong>. Simple but effective, our implementation partitions the matrices’ iteration space though such strip mining and loop interchange</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">s</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="n">s2</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">colAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="n">s3</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount2</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">rowAmount1</span> <span class="o">/</span> <span class="n">s</span><span class="o">;</span> <span class="n">i</span><span class="o">+=</span><span class="n">s</span><span class="o">){</span>
</span><span class='line'>  <span class="k">for</span> <span class="o">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">colAmount1</span> <span class="o">/</span> <span class="n">s2</span><span class="o">;</span> <span class="n">j</span><span class="o">+=</span><span class="n">s2</span><span class="o">){</span>
</span><span class='line'>    <span class="k">for</span> <span class="o">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span> <span class="o">/</span><span class="n">s3</span><span class="o">;</span> <span class="n">k</span><span class="o">+=</span><span class="n">s3</span><span class="o">){</span>
</span><span class='line'>      <span class="k">for</span> <span class="o">(</span><span class="n">i2</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span> <span class="n">i2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">i</span><span class="o">+</span><span class="n">s</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">i2</span> <span class="o">&lt;</span> <span class="n">rowAmount1</span><span class="o">;</span> <span class="n">i2</span><span class="o">++){</span>
</span><span class='line'>        <span class="k">for</span> <span class="o">(</span><span class="n">j2</span> <span class="o">=</span> <span class="n">j</span><span class="o">;</span> <span class="n">j2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">j</span><span class="o">+</span><span class="n">s2</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">j2</span> <span class="o">&lt;</span> <span class="n">colAmount1</span><span class="o">;</span> <span class="n">j2</span><span class="o">++){</span>
</span><span class='line'>          <span class="k">for</span> <span class="o">(</span><span class="n">k2</span> <span class="o">=</span> <span class="n">k</span><span class="o">;</span> <span class="n">k2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">k</span><span class="o">+</span><span class="n">s3</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">k2</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span><span class="o">;</span> <span class="n">k2</span><span class="o">++){</span>
</span><span class='line'>            <span class="n">C</span><span class="o">[</span><span class="n">i2</span><span class="o">][</span><span class="n">j2</span><span class="o">]</span> <span class="o">+=</span> <span class="o">(</span><span class="n">A</span><span class="o">[</span><span class="n">i2</span><span class="o">][</span><span class="n">k2</span><span class="o">]</span> <span class="err">∗</span> <span class="n">B</span><span class="o">[</span><span class="n">k2</span><span class="o">][</span><span class="n">j2</span><span class="o">]);</span>
</span><span class='line'>                          <span class="o">....</span>
</span></code></pre></td></tr></table></div></figure>


<p>Although not implemented recursively, tiling shares some similarities to the divide-and-conquer approach in that it aims to refine the problem size through partitioning the problems (matrices) into subproblems (submatrices). The design of the tiling solution quite naturally lends itself to parallelisation. Such is implemented as follows</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">s</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="n">s2</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">colAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="n">s3</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount2</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span><span class="o">);</span>
</span><span class='line'><span class="n">executor</span> <span class="o">=</span> <span class="n">Executors</span><span class="o">.</span><span class="na">newFixedThreadPool</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
</span><span class='line'><span class="k">for</span><span class="o">(</span><span class="n">interval</span> <span class="o">=</span> <span class="mi">10</span><span class="o">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">rowAmount1</span><span class="o">,</span>
</span><span class='line'>    <span class="n">size</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">10</span><span class="o">);</span>
</span><span class='line'>    <span class="n">interval</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">end</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">;</span> <span class="n">interval</span><span class="err">−−</span><span class="o">,</span> <span class="n">end</span> <span class="err">−</span><span class="o">=</span> <span class="n">size</span><span class="o">){</span>
</span><span class='line'>  <span class="n">to</span> <span class="o">=</span> <span class="n">end</span><span class="o">;</span>
</span><span class='line'>  <span class="n">from</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">end</span> <span class="err">−</span> <span class="n">size</span><span class="o">);</span>
</span><span class='line'>  <span class="n">Runnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Runnable</span><span class="o">(){</span>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">from</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">to</span> <span class="o">/</span> <span class="n">s</span><span class="o">;</span> <span class="n">i</span><span class="o">+=</span><span class="n">s</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">for</span> <span class="o">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">colAmount1</span> <span class="o">/</span> <span class="n">s2</span><span class="o">;</span> <span class="n">j</span><span class="o">+=</span><span class="n">s2</span><span class="o">){</span>
</span><span class='line'>          <span class="k">for</span> <span class="o">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span> <span class="o">/</span><span class="n">s3</span><span class="o">;</span> <span class="n">k</span><span class="o">+=</span><span class="n">s3</span><span class="o">){</span>
</span><span class='line'>            <span class="k">for</span> <span class="o">(</span><span class="n">i2</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span> <span class="n">i2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">i</span><span class="o">+</span><span class="n">s</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">i2</span> <span class="o">&lt;</span> <span class="n">rowAmount1</span><span class="o">;</span> <span class="n">i2</span><span class="o">++){</span>
</span><span class='line'>              <span class="k">for</span> <span class="o">(</span><span class="n">j2</span> <span class="o">=</span> <span class="n">j</span><span class="o">;</span> <span class="n">j2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">j</span><span class="o">+</span><span class="n">s2</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">j2</span> <span class="o">&lt;</span> <span class="n">colAmount1</span><span class="o">;</span> <span class="n">j2</span><span class="o">++){</span>
</span><span class='line'>                <span class="k">for</span> <span class="o">(</span><span class="n">k2</span> <span class="o">=</span> <span class="n">k</span><span class="o">;</span> <span class="n">k2</span> <span class="o">&lt;</span> <span class="o">(</span><span class="n">k</span><span class="o">+</span><span class="n">s3</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">k2</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span><span class="o">;</span> <span class="n">k2</span><span class="o">++){</span>
</span><span class='line'>                  <span class="n">C</span><span class="o">[</span><span class="n">i2</span><span class="o">][</span><span class="n">j2</span><span class="o">]</span> <span class="o">+=</span> <span class="o">(</span><span class="n">A</span><span class="o">[</span><span class="n">i2</span><span class="o">][</span><span class="n">k2</span><span class="o">]</span> <span class="err">∗</span> <span class="n">B</span><span class="o">[</span><span class="n">k2</span><span class="o">][</span><span class="n">j2</span><span class="o">]);</span>
</span><span class='line'>                               <span class="o">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is important to note the <strong>s</strong>, <strong>s2</strong> and <strong>s3</strong> parameters to our tiling algorithm. Above we see that they are derived respectively from a matrix dimension divided by 4. They are then later used to determine the dimensions (size <strong>s2</strong>x<strong>s3</strong>) of the submatrix-submatrix multiply tasks to be ran. In the case of a square MMM the submatrices’ dimensions would be <strong>s</strong>x<strong>s</strong>.</p>

<p>We divide up these multiply tasks through from/to bounds - requiring no synchronisation as no mutable data is shared across threads.</p>

<p>Determining values for <strong>s</strong>, <strong>s2</strong> and <strong>s3</strong> is not straight-forward, they ultimately determine the tiling size which in turn demands an accurate estimate of the cache size on your target machine. Assuming square matrices which do not fit into a tall cache then</p>

<p style="text-align:center;">n = rowAmountOfA = colAmountOfA = rowAmountOfB</p>

<p style="text-align:center;">n > M/B</p>

<p>Once we determine <strong>s &#8804; M/B</strong> we can easily decompose submatrices (tiles) from matrix <strong>B</strong> that respect the target cache size</p>

<p><img src="/images/tiled.png" alt="m" /></p>

<p>As you would expect the tiling optimisation still results in <strong>Θ(n<sup>3</sup>)</strong> computations. With an optimal <strong>s</strong> value, <strong>Θ(M<sup>&frac12;</sup>)</strong>, we see an improvement in the amount of work done to that of our naive approach. The tall-cache assumption implies that each submatrix and its data will fit in cache, meaning only cold caches misses should occur per submatrix (<strong>Θ(s<sup>2</sup>/B)</strong>).</p>

<p style="text-align:center;">Θ(n) = Θ((n/s)<sup>3</sup>(s<sup>3</sup>)) = Θ(n<sup>3</sup>)</p>

<p style="text-align:center;">Q(n) = Θ((n/s)<sup>3</sup>(s<sup>2</sup>/B)) = Θ(n<sup>3</sup>/BM<sup>&frac12;</sup>)</p>

<p>From the above, as you might have guessed, we can see that <strong>s</strong> is actually a &ldquo;tuning&rdquo; parameter for cache-awareness. In our solution this tiling dividend is set to 4 which, from some rudimentary testing, is the optimal value on recent i5 and i7 processors (OS X 10.10).</p>

<h2>Dem Benchmarks: What was measured?</h2>

<p>Our benchmarking goal was to analyse the trends displayed across the executions of naive MMM and cache-aware MMM in conjunction with parallelisation. Thus the benchmarking process undertaken had the following features:</p>

<ol>
<li>A varying set of dimensions for <strong>A</strong> and <strong>B</strong> respectively on both algorithms were used to identify trends. The dimensions (200x200), (200x300), (1000x1000) and (1000x1200) were used.</li>
<li>To maintain measurement accuracy the elements held by <strong>A</strong> and <strong>B</strong> needed to be the same for each measurement. Every element held by <strong>A</strong> is always 2, while each element in <strong>B</strong> is always 3.</li>
<li>Each benchmark was conducted on two machines (4 core and 8 cores) under the same conditions (no other user processes running, machines connected to power outlets, etc.)</li>
</ol>


<p><img src="/images/i5.png" alt="m" /></p>

<p><img src="/images/i7.png" alt="m" /></p>

<h2>Dem Results</h2>

<p>Reflecting on the mean (μ) execution-time and according standard deviation (σ) provided by our benchmark runs, the collated results are as follows</p>

<p><img src="/images/res.png" alt="m" /></p>

<p>Our data poses several interesting avenues of investigation. However our main concern is exploring the benefits of cache-aware algorithms, so lets just explore the performance differences between both algorithms across runs. The bellow sidebar chart illustrates an obvious difference in our algorithms, at a glance one can see that there is large deviation between the naive and tiled time results.</p>

<p><img src="/images/data.png" alt="m" /></p>

<p>This is particularly true across the benchmarks where matrix dimensions are in their thousands. Such is unsurprising given that the naive algorithm is cache-oblivious. When viewing every sidebar related to the tiled results we can see that varying matrix dimensions do not greatly affect performance. Interestingly, we see that an increase in cores only greatly benefits the naive algorithm. It sees around a 55% improvement in execution-time with the assistance of 4 extra cores across all dimension sizes.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="/categories/#concurrency" title="Pages tagged concurrency" class="tag">concurrency</a><a href="/categories/#java" title="Pages tagged java" class="tag">java</a><a href="/categories/#research" title="Pages tagged research" class="tag">research</a></span>
        <span><a href="/blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2/" rel="bookmark" title="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)">Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 2)</a> was published on <span class="entry-date date published updated"><time datetime="2015-08-24T19:56:46+01:00">August 24, 2015</time></span></span>
        
        <span class="author vcard"><span class="fn"><a href="" title="About Anthony Troy">Anthony Troy</a></span></span>
        
      </footer>
    </div><!-- /.entry-content -->
      
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2017 Anthony Troy. Powered by <a href="http://octopress.org">Octopress</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/javascripts/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<!--
<script src="/javascripts/octopress.js" type="text/javascript"></script>
-->
<script src="/javascripts/scripts.min.js"></script>




<script type="text/javascript">
      var disqus_shortname = 'toekneeland';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2/';
        var disqus_url = 'http://blog/2015/08/24/matrix-multiply-naive-vs-cache-aware-approaches-part-2/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>




</body>
</html>
