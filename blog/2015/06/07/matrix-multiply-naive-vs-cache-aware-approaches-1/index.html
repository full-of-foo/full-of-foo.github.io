
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->

<head>


<meta charset="utf-8">
<meta http-equiv="cleartype" content="on">

<title>(╯°□°）╯︵ ┻━┻ Matrix Multiply: Naive vs Cache-Aware Approaches (Part 1) - </title>
<meta name="author" content="Anthony Troy">




<meta name="description" content="Why, Why, Why? Before undertaking my postgraduate studies I led a quite joyous and sheltered life. Living the high life in the worlds of Ruby, &hellip;">

<meta name="keywords" content="concurrency java research blog ruby rails javascript coffeescript backbone modern tech hacks dublin">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Twitter Cards -->

  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content"">
  
  <meta name="twitter:title" content="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)">
  <meta name="twitter:description" content="Why, Why, Why? Before undertaking my postgraduate studies I led a quite joyous and sheltered life. Living the high life in the worlds of Ruby, &hellip;">
  <meta name="twitter:creator" content="@devtoeknee">


<!-- Open Graph -->
<meta property="og:local" content="en_US">
<meta property="og:type" content="article">
<meta property="og:url" content="http:///blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1">
<meta property="og:title" content="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)">
<meta property="og:description" content="Why, Why, Why? Before undertaking my postgraduate studies I led a quite joyous and sheltered life. Living the high life in the worlds of Ruby, &hellip;">

  <meta property="og:image" content="">

<meta property="og:site_name" content="">

<link rel="canonical" href="http:///blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1">
<link href="/favicon.png" rel="icon">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link href="/atom.xml" rel="alternate" title="" type="application/atom+xml">
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/javascripts/vendor/modernizr-2.6.2.custom.min.js"></script>



<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">


</head>

<body id="post" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpeg" alt="Anthony Troy photo" class="author-photo">
					<h4>Anthony Troy</h4>
					<p>Code Pirate, </br>Project Monkey</p>
				</li>
				<li><a target="_blank" href="//ie.linkedin.com/pub/anthony-troy/62/40a/743">Learn More</a></li>
				
				<li>
					<a target="_blank" href="http://twitter.com/devtoeknee"><i class="fa fa-twitter"></i> Twitter</a>
				</li>
				
				<li>
					<a target="_blank" href="http://github.com/full-of-foo"><i class="fa fa-github"></i> GitHub</a>
				</li>
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->




<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="/blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1/" rel="bookmark" title="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)">Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)</a></h1>
        
        <h2>June 07, 2015</h2>
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <h2>Why, Why, Why?</h2>

<p>Before undertaking my postgraduate studies I led a quite joyous and sheltered life. Living the high life in the worlds of Ruby, Javascript, Python, Java and all of those sorts. My life got flipped-turned upside down when I began studying subjects like Secure Programming, Concurrent Programming and Formal Methods. For me, the biggest take-aways from these learnings were <a href="http://en.wikipedia.org/wiki/Parallel_algorithm">parallel algorithm design</a> and the <a href="http://en.wikipedia.org/wiki/Locality_of_reference">principle of locality</a>.
<img src="/images/fresh.png" alt="fresh" /></p>

<p>Most dense linear algebraic computations rely on the consideration of both spatial and temporal locality. If you are unfamiliar with locality, the former describes the tendency of applications to reference memory addresses that are near other recently accessed addresses and the latter describes the amount of reuse of the same memory locations.</p>

<p>One such linear algebra problem subject to this is dense <a href="http://en.wikipedia.org/wiki/Matrix_multiplication">Matrix-Matrix multiplication (MMM)</a>. Coincidentally MMM is also highly highly parallelisable so it is a perfect to demonstrate <a href="http://en.wikipedia.org/wiki/Parallel_algorithm">parallel algorithm design</a> and the <a href="http://en.wikipedia.org/wiki/Locality_of_reference">principle of locality</a>.</p>

<h2>Matrix Multiply, Ain&rsquo;t Nobody Got Time For That</h2>

<p>Matrix multiplication is important, it is actually central to many scientific computations. For instance, solving a linear system or least-square fits of coefficients to data rely on MMM implementations for good performance.</p>

<p>As you would expect, the performance of an MMM implementation is intimately related to the memory layout of the arrays. On modern shared-memory multiprocessors with multi-level memory hierarchies, naive access patterns in the memory hierarchy can incur cache capacity misses.</p>

<h2>Matrix Multiply, How Tho?</h2>

<p>MMM for square matrices has the following mathematical definition (which is independent of any implementation). Given two n x n matrices A and B, the sum and product</p>

<p style="text-align:center;">C + A ·B</p>

<p>For non-square matrices MMM differs in that the amount of columns in
matrix A must equal equal the amount of rows in B.</p>

<h2>Naive Matrix-Matrix Multiply</h2>

<p>The most naive algorithm for MMM comes straight from the above definition and mimics computing the product by hand. Assuming the arrays are stored such that rows of the arrays are in consecutive memory locations, i.e. row-major order, then we derive C as follows</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">rowAmount1</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span>
</span><span class='line'>  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">colAmount1</span><span class="o">;</span> <span class="n">j</span><span class="o">++)</span>
</span><span class='line'>      <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span><span class="o">;</span> <span class="n">k</span><span class="o">++)</span>
</span><span class='line'>          <span class="n">C</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">]</span> <span class="o">+=</span> <span class="o">(</span><span class="n">A</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span><span class="o">]</span> <span class="err">∗</span> <span class="n">B</span><span class="o">[</span><span class="n">k</span><span class="o">][</span><span class="n">j</span><span class="o">]);</span>
</span></code></pre></td></tr></table></div></figure>


<p>This algorithm is said to be naive because it suffers from poor locality. Elements of B are accessed column-wise, and therefore not in sequential order in memory. While each iteration in j reuses row i of A, that row may have been evicted from the cache by the time the inner-most loop completes. As a result, the algorithm is bandwidth limited and displays poor performance and low efficiency.</p>

<p>As we highlighted before, matrix multiplications have abundant parallel computation. While maintaining the less favourable design of this naive approach, let us introduce a parallelised implementation</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">executor</span> <span class="o">=</span> <span class="n">Executors</span><span class="o">.</span><span class="na">newFixedThreadPool</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span> <span class="o">;</span>
</span><span class='line'><span class="k">for</span> <span class="o">(</span><span class="n">interval</span> <span class="o">=</span> <span class="n">numTasks</span><span class="o">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">rowAmount1</span><span class="o">,</span>
</span><span class='line'>      <span class="n">size</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">Math</span><span class="o">.</span><span class="na">ceil</span><span class="o">(</span><span class="n">rowAmount1</span> <span class="err">∗</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">10</span><span class="o">);</span>
</span><span class='line'>      <span class="n">interval</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">end</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">;</span> <span class="n">interval</span><span class="err">−−</span><span class="o">,</span> <span class="n">end</span> <span class="err">−</span><span class="o">=</span> <span class="n">size</span><span class="o">){</span>
</span><span class='line'>  <span class="kd">final</span> <span class="kt">int</span> <span class="n">to</span> <span class="o">=</span> <span class="n">end</span><span class="o">;</span>
</span><span class='line'>  <span class="kd">final</span> <span class="kt">int</span> <span class="n">from</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">end</span> <span class="err">−</span> <span class="n">size</span><span class="o">);</span>
</span><span class='line'>  <span class="n">Runnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Runnable</span><span class="o">(){</span>
</span><span class='line'>      <span class="nd">@Override</span>
</span><span class='line'>      <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">(){</span>
</span><span class='line'>          <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">from</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">to</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span>
</span><span class='line'>              <span class="k">for</span> <span class="o">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">colAmount1</span><span class="o">;</span> <span class="n">j</span><span class="o">++)</span>
</span><span class='line'>                  <span class="k">for</span> <span class="o">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">rowAmount2</span><span class="o">;</span> <span class="n">k</span><span class="o">++)</span>
</span><span class='line'>                      <span class="n">C</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">]</span> <span class="o">+=</span> <span class="o">(</span><span class="n">A</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">k</span><span class="o">]</span> <span class="err">∗</span> <span class="n">B</span><span class="o">[</span><span class="n">k</span><span class="o">][</span><span class="n">j</span><span class="o">]);</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">};</span>
</span><span class='line'>  <span class="n">executor</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="n">runnable</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We must manually divide the work up into tasks and provide each task with its from/to bounds. Each task will run the entire outer loop but for only specific non-overlapping values. Thus there is no synchronisation in this implementation as no mutable data is shared across threads. The input arrays A and B are not mutated. While the contents of output array C are altered, each thread works on different slices.</p>

<h2>What&rsquo;s The Actual Damage Tho?</h2>

<p>When working with most matrix sizes this approach sees significant improvements in execution time against its sequential counterpart. However as you may expect these improvements are not linear against different matrix sizes.</p>

<p>The basic flaw of the naive triple-for-loop implementation is that the size of its per-loop working set prevents bandwidth amplification from the closest levels of the memory hierarchy, i.e. even with this parallelised horizontal-slicing approach the algorithm <strong>still suffers from poor locality</strong>.</p>

<h2>Until Next Time</h2>

<p><img src="/images/will.png" alt="will" />
Later on we shall investigate some fun stuff like Cache-Awareness and the Tall-Cache Assumption. Of course we&rsquo;ll then develop a cache-aware MMM algorithm using a &ldquo;tiling&rdquo; approach. Finally we will see some pretty benchmark graphs that demonstrate how our algorithms fared across different matrix sizes over a different number of cores.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="/categories/#concurrency" title="Pages tagged concurrency" class="tag">concurrency</a><a href="/categories/#java" title="Pages tagged java" class="tag">java</a><a href="/categories/#research" title="Pages tagged research" class="tag">research</a></span>
        <span><a href="/blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1/" rel="bookmark" title="Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)">Matrix Multiply: Naive Vs Cache-Aware Approaches (Part 1)</a> was published on <span class="entry-date date published updated"><time datetime="2015-06-07T17:12:21+01:00">June 07, 2015</time></span></span>
        
        <span class="author vcard"><span class="fn"><a href="" title="About Anthony Troy">Anthony Troy</a></span></span>
        
      </footer>
    </div><!-- /.entry-content -->
      
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2017 Anthony Troy. Powered by <a href="http://octopress.org">Octopress</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/javascripts/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<!--
<script src="/javascripts/octopress.js" type="text/javascript"></script>
-->
<script src="/javascripts/scripts.min.js"></script>




<script type="text/javascript">
      var disqus_shortname = 'toekneeland';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1/';
        var disqus_url = 'http://blog/2015/06/07/matrix-multiply-naive-vs-cache-aware-approaches-1/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>




</body>
</html>
